{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6d88d3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, GRU, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "51cb4ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"IMDB Dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c4802903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['review', 'sentiment'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "089b9e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()  \n",
    "    text = re.sub(r'<.*?>', '', text)  \n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a85575f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review\"] = df[\"review\"].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment\"] = df[\"sentiment\"].apply(lambda x: 1 if x == \"positive\" else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"review\"]\n",
    "y = df[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "631a751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"review\"].astype(str)\n",
    "labels = df[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 20000\n",
    "max_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f7d7847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "26e40eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6544fab2",
   "metadata": {},
   "source": [
    "GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4885c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_index = {}\n",
    "with open(\"C:/Users/mwtok/OneDrive/Desktop/glove.6B/glove.6B.100d.txt\", encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ab26631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "word_index = tokenizer.word_index\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291e644a",
   "metadata": {},
   "source": [
    "LTSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d13d12d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 156ms/step - accuracy: 0.6334 - loss: 0.6389 - val_accuracy: 0.7936 - val_loss: 0.4550\n",
      "Epoch 2/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 144ms/step - accuracy: 0.7920 - loss: 0.4598 - val_accuracy: 0.8389 - val_loss: 0.3738\n",
      "Epoch 3/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 140ms/step - accuracy: 0.8437 - loss: 0.3569 - val_accuracy: 0.8599 - val_loss: 0.3254\n",
      "Epoch 4/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 142ms/step - accuracy: 0.8625 - loss: 0.3211 - val_accuracy: 0.8636 - val_loss: 0.3133\n",
      "Epoch 5/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 144ms/step - accuracy: 0.8768 - loss: 0.2895 - val_accuracy: 0.8685 - val_loss: 0.3064\n",
      "Epoch 6/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 140ms/step - accuracy: 0.8873 - loss: 0.2725 - val_accuracy: 0.8746 - val_loss: 0.2976\n",
      "Epoch 7/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 144ms/step - accuracy: 0.8980 - loss: 0.2530 - val_accuracy: 0.8765 - val_loss: 0.2939\n",
      "Epoch 8/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 142ms/step - accuracy: 0.9110 - loss: 0.2265 - val_accuracy: 0.8734 - val_loss: 0.3039\n",
      "Epoch 9/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 143ms/step - accuracy: 0.9201 - loss: 0.2015 - val_accuracy: 0.8792 - val_loss: 0.2926\n",
      "Epoch 10/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 143ms/step - accuracy: 0.9339 - loss: 0.1723 - val_accuracy: 0.8808 - val_loss: 0.2935\n",
      "Epoch 11/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 144ms/step - accuracy: 0.9451 - loss: 0.1453 - val_accuracy: 0.8714 - val_loss: 0.3550\n",
      "Epoch 12/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 143ms/step - accuracy: 0.9564 - loss: 0.1172 - val_accuracy: 0.8712 - val_loss: 0.3594\n",
      "Epoch 13/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 145ms/step - accuracy: 0.9671 - loss: 0.0932 - val_accuracy: 0.8736 - val_loss: 0.4018\n",
      "Epoch 14/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 146ms/step - accuracy: 0.9751 - loss: 0.0744 - val_accuracy: 0.8695 - val_loss: 0.4288\n",
      "Epoch 15/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 161ms/step - accuracy: 0.9802 - loss: 0.0563 - val_accuracy: 0.8669 - val_loss: 0.4781\n",
      "Epoch 16/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 154ms/step - accuracy: 0.9851 - loss: 0.0480 - val_accuracy: 0.8683 - val_loss: 0.5412\n",
      "Epoch 17/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 152ms/step - accuracy: 0.9886 - loss: 0.0357 - val_accuracy: 0.8669 - val_loss: 0.5558\n",
      "Epoch 18/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 147ms/step - accuracy: 0.9930 - loss: 0.0251 - val_accuracy: 0.8630 - val_loss: 0.5574\n",
      "Epoch 19/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 144ms/step - accuracy: 0.9930 - loss: 0.0239 - val_accuracy: 0.8664 - val_loss: 0.5963\n",
      "Epoch 20/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 139ms/step - accuracy: 0.9939 - loss: 0.0209 - val_accuracy: 0.8654 - val_loss: 0.6234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a76b42d070>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False),\n",
    "    LSTM(128),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "lstm_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "lstm_model.fit(X_train_pad, y_train, epochs=20, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0cab886c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step\n",
      "🔹 LSTM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8596    0.8809    0.8701      4961\n",
      "           1     0.8798    0.8583    0.8689      5039\n",
      "\n",
      "    accuracy                         0.8695     10000\n",
      "   macro avg     0.8697    0.8696    0.8695     10000\n",
      "weighted avg     0.8697    0.8695    0.8695     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_preds = (lstm_model.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
    "print(\"🔹 LSTM Classification Report:\")\n",
    "print(classification_report(y_test, lstm_preds, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81d812f",
   "metadata": {},
   "source": [
    "GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "05d8f20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 135ms/step - accuracy: 0.6933 - loss: 0.5627 - val_accuracy: 0.8505 - val_loss: 0.3425\n",
      "Epoch 2/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 133ms/step - accuracy: 0.8502 - loss: 0.3475 - val_accuracy: 0.8691 - val_loss: 0.3075\n",
      "Epoch 3/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 131ms/step - accuracy: 0.8701 - loss: 0.3049 - val_accuracy: 0.8781 - val_loss: 0.2870\n",
      "Epoch 4/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 135ms/step - accuracy: 0.8865 - loss: 0.2711 - val_accuracy: 0.8813 - val_loss: 0.2834\n",
      "Epoch 5/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 134ms/step - accuracy: 0.8979 - loss: 0.2502 - val_accuracy: 0.8852 - val_loss: 0.2763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a753da0a40>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False),\n",
    "    GRU(128),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "gru_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "gru_model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "faf8ec02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step\n",
      "🔹 GRU Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8970    0.8690    0.8828      4961\n",
      "           1     0.8749    0.9018    0.8881      5039\n",
      "\n",
      "    accuracy                         0.8855     10000\n",
      "   macro avg     0.8859    0.8854    0.8854     10000\n",
      "weighted avg     0.8858    0.8855    0.8855     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gru_preds = (gru_model.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
    "print(\"🔹 GRU Classification Report:\")\n",
    "print(classification_report(y_test, gru_preds, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e296859",
   "metadata": {},
   "source": [
    "rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "05f9948e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 34ms/step - accuracy: 0.5844 - loss: 0.6744 - val_accuracy: 0.6160 - val_loss: 0.6506\n",
      "Epoch 2/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - accuracy: 0.6365 - loss: 0.6361 - val_accuracy: 0.7055 - val_loss: 0.5867\n",
      "Epoch 3/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 33ms/step - accuracy: 0.6421 - loss: 0.6346 - val_accuracy: 0.7013 - val_loss: 0.5848\n",
      "Epoch 4/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 33ms/step - accuracy: 0.6387 - loss: 0.6355 - val_accuracy: 0.5601 - val_loss: 0.6710\n",
      "Epoch 5/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 33ms/step - accuracy: 0.6176 - loss: 0.6456 - val_accuracy: 0.5450 - val_loss: 0.7020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a74d388980>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False),\n",
    "    SimpleRNN(128),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "rnn_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "rnn_model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "02c12fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step\n",
      "Simple RNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5220    0.9546    0.6749      4961\n",
      "           1     0.7573    0.1393    0.2353      5039\n",
      "\n",
      "    accuracy                         0.5438     10000\n",
      "   macro avg     0.6396    0.5470    0.4551     10000\n",
      "weighted avg     0.6406    0.5438    0.4534     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn_preds = (rnn_model.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
    "print(\"Simple RNN Classification Report:\")\n",
    "print(classification_report(y_test, rnn_preds, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "lstm_model.save(\"lstm_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a8fc3c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
